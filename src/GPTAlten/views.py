from django.shortcuts import render
from django.http import JsonResponse
import os 
from os import path as modelpath
import openai
from pathlib import Path
from django.views.decorators.csrf import csrf_exempt
from transformers import pipeline, BartForConditionalGeneration, BartTokenizer
import warnings


# Ignore possible warnings from librairies
warnings.filterwarnings('ignore')

BASE_DIR = Path(__file__).resolve().parent.parent
openai.api_key =  open(os.path.join(BASE_DIR, 'GPTAlten/openai/openai_api_key.txt'), "r").read()

BART_path = 'GPTAlten/models/BART' 
BART_token_path = 'GPTAlten/models/BART_token' 

if modelpath.exists(BART_path) is False and modelpath.exists(BART_token_path) is False:
    print("if marche")
    # if model is on hugging face Hub
    tokenizer = BartTokenizer.from_pretrained("facebook/bart-large")
    model = BartForConditionalGeneration.from_pretrained("facebook/bart-large")

def generate_openai_response(text):
        """Generate the summarized sentence made by OpenAI

        Args:
            text (str): Text given to OpenAI model

        Returns:
            gpt_answer (str): Answer generated by GPT-3 model
        """
        openai_input = text 
        gpt_answer = openai.Completion.create(
                engine='text-davinci-003',              # Model selected. Determines the quality, speed, and cost.
                temperature=0.5,                        # Level of creativity in the response
                prompt=openai_input,                    # What the user typed in
                max_tokens=1024,                         # Maximum tokens in the prompt AND response
                n=1,                                    # The number of completions to generate
                stop=None,                              # An optional setting to control response generation
                ).choices[0].text
        # Return the first choice's text
        return gpt_answer

@csrf_exempt
def get_response(request):
    response = {}
    if request.method == 'POST':
        message = request.POST.get('message')
        print('message', message)
        try:
            chat_response = generate_openai_response(message)
        except Exception as error:
            chat_response = str(error)
        print('chat_response', chat_response)
        response['result'] = chat_response
    return JsonResponse(response)

@csrf_exempt
def summarize(request, model_selected="OpenAI"):
        """Application of the different models on text

        Args:
            list_text (list): List of text to summarize
            model (str): Large Language Model desired. Defaults to "OpenAI".

        Returns:
            list_answer (list): List of summary made
        """
        response = {}
        if request.method == 'POST':
            text = request.POST.get('message')
            model_selected = request.POST.get('model')
            # print('text', text)
            # print('model_selected', model_selected)
            try:
                if model_selected == "BART":
                    print('BART is SELECTED')
                    model = BartForConditionalGeneration.from_pretrained(BART_path)
                    tokenizer = BartTokenizer.from_pretrained(BART_token_path)
                    summarizer = pipeline("summarization", model=model, tokenizer=tokenizer)
                    summary = summarizer(text)[0].get('summary_text')
                elif model_selected == "ChatGPT":
                    print('ChatGPT is SELECTED')
                    openai_input ='Summarize the following sentence : '+text 
                    summary = generate_openai_response(openai_input)
            except Exception as error:
                summary = str(error)
        print('summary', summary)
        response['result'] = summary
        return JsonResponse(response)

def index(request):
    return render(request, "index.html")

def homepage(request):
    return render(request, "homepage.html")

def traducteur(request):
    return render(request, "traducteur.html")

def chatbot(request):
    return render(request, "chatbot.html")

def tutoriel(request):
    return render(request, "tutoriel.html")

def synth(request):
    return render(request, "synth.html")

def benchmark(request):
    return render(request, "benchmark.html")